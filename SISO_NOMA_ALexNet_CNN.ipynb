{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# import the necessary packages\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import math\n",
        "\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "from tensorflow.keras.optimizers import SGD, RMSprop, Adam\n",
        "\n",
        "\n",
        "np.random.seed(1000)"
      ],
      "metadata": {
        "id": "GUGqgaRqMqq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_data(N, M, batch_size):\n",
        "    a = np.array(range(pow(2, N)))\n",
        "    K = np.tile(a, batch_size)\n",
        "    data = K\n",
        "\n",
        "    a = np.eye(modulation_order)\n",
        "    K = np.tile(a, batch_size)\n",
        "    label = np.transpose(K)\n",
        "    return data, label\n",
        "\n",
        "\n",
        "def generate(M, N, batch_size):\n",
        "    data,label = generate_data(N, M, batch_size)\n",
        "\n",
        "    ran1 = np.random.permutation(batch_size * pow(2, N))\n",
        "    ran2 = np.random.permutation(batch_size * pow(2, N))\n",
        "\n",
        "    symbol1 = 2 * data[ran1] - 1\n",
        "    symbol2 = 2 * data[ran2] - 1\n",
        "\n",
        "    SPC = math.sqrt(0.8) * symbol1 +math.sqrt(0.2) * symbol2\n",
        "\n",
        "    label1 = label[ran1,:].astype('float32')\n",
        "    label2 = label[ran2,:].astype('float32')\n",
        "\n",
        "    return SPC, label1, label2\n",
        "\n",
        "\n",
        "def generate_input(H1_real, H1_image, SPC, N, batch_size, sigma):\n",
        "\n",
        "    N_real, N_image = generate_channel(N, batch_size * pow(2, N), 0)\n",
        "\n",
        "    input1_real = H1_real * SPC + sigma * N_real\n",
        "    input1_img = H1_image * SPC + sigma * N_image\n",
        "\n",
        "    input1 = np.transpose(np.concatenate((input1_real, input1_img), axis=0))\n",
        "\n",
        "    return input1\n",
        "\n",
        "\n",
        "def generate_channel(N, M, k):\n",
        "    h1 = np.random.randn(N, M) / math.sqrt(2)\n",
        "    h2 = np.random.randn(N, M) / math.sqrt(2)\n",
        "\n",
        "    if k == 0:\n",
        "        return h1, h2\n",
        "    else:\n",
        "        return 2 * h1, 2 * h2\n",
        ""
      ],
      "metadata": {
        "id": "DU0_N1O3Min5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_alex_cnn():\n",
        "    #Instantiate an empty model\n",
        "    model = Sequential()\n",
        "\n",
        "    # 1st Convolutional Layer\n",
        "    model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11), strides=(4,4), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Max Pooling\n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "\n",
        "    # 2nd Convolutional Layer\n",
        "    model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Max Pooling\n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "\n",
        "    # 3rd Convolutional Layer\n",
        "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    # 4th Convolutional Layer\n",
        "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    # 5th Convolutional Layer\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    # Max Pooling\n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "\n",
        "    # Passing it to a Fully Connected layer\n",
        "    model.add(Flatten())\n",
        "    # 1st Fully Connected Layer\n",
        "    model.add(Dense(4096, input_shape=(224*224*3,)))\n",
        "    model.add(Activation('relu'))\n",
        "    # Add Dropout to prevent overfitting\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    # 2nd Fully Connected Layer\n",
        "    model.add(Dense(4096))\n",
        "    model.add(Activation('relu'))\n",
        "    # Add Dropout\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    # 3rd Fully Connected Layer\n",
        "    model.add(Dense(1000))\n",
        "    model.add(Activation('relu'))\n",
        "    # Add Dropout\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(Dense(modulation_order))\n",
        "    model.add(Activation('sigmoid'))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "R8aB-TRB3UUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def my_loss(y_t , y_p) :\n",
        "    m_loss = tf.reduce_mean(tf.compat.v2.nn.softmax_cross_entropy_with_logits(logits=y_p, labels=y_t))\n",
        "    return m_loss\n",
        "\n",
        "def my_acc(y_t, y_p):\n",
        "    print(y_p.shape)\n",
        "    print(y_t.shape)\n",
        "    K.print_tensor(y_t)\n",
        "    K.print_tensor(y_p)\n",
        "    correct_prediction = tf.equal(tf.argmax(y_p, axis= 1), tf.argmax(y_t, axis= 1))\n",
        "    acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "    return acc"
      ],
      "metadata": {
        "id": "W7Zjh2q_Owpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# network and training\n",
        "VERBOSE = \"auto\"\n",
        "OPTIMIZER = Adam(epsilon= 5e-04)\n",
        "VALIDATION_SPLIT=0.3\n",
        "N = 1\n",
        "M = 1\n",
        "n_symbol = 100\n",
        "n_iteration = 1\n",
        "NB_EPOCH = 3\n",
        "modulation_order = 2\n",
        "\n",
        "SNR_db = np.array(list(range(0, 11, 2)))\n",
        "# SNR_db = np.array(list(range(100,101)))\n",
        "batch_size = 224*224*3\n",
        "test_size = 0.5\n",
        "\n",
        "ERROR_user1 = np.zeros([len(SNR_db), n_iteration])\n",
        "ERROR_user2 = np.zeros([len(SNR_db), n_iteration])"
      ],
      "metadata": {
        "id": "BTtAac8gO3zA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(n_iteration):\n",
        "    H1_real, H1_image = generate_channel(N, M, 0)\n",
        "    H2_real, H2_image = generate_channel(N, M, 1)\n",
        "    print ('training iteration %d' %(k))\n",
        "\n",
        "    for i in range(len(SNR_db)):\n",
        "\n",
        "        SPC, label1, _ = generate(M, N,  batch_size)\n",
        "        signal_power = np.mean(pow(SPC, 2))\n",
        "        sigma = math.sqrt(signal_power / (math.sqrt(N) * pow(10, SNR_db[i] / 10)))\n",
        "        input1_train = generate_input(H1_real, H1_image, SPC, N,  batch_size, sigma)\n",
        "        input1_train = tf.reshape(input1_train, [-1, 224, 224, 3])\n",
        "        # initialize the optimizer and model\n",
        "        model_d1 = model_alex_cnn()\n",
        "        model_d1.compile(loss=my_loss, optimizer=OPTIMIZER,metrics=[my_acc])\n",
        "        history_d1 = model_d1.fit(input1_train, label1, epochs=NB_EPOCH,verbose=VERBOSE ,validation_split=VALIDATION_SPLIT )\n",
        "\n",
        "\n",
        "    for i in range(len(SNR_db)):\n",
        "\n",
        "        SPC, _, label2 = generate(M, N,  batch_size)\n",
        "        signal_power = np.mean(pow(SPC, 2))\n",
        "        sigma = math.sqrt(signal_power / (math.sqrt(N) * pow(10, SNR_db[i] / 10)))\n",
        "        input2_train = generate_input(H2_real, H2_image, SPC, N, batch_size, sigma)\n",
        "        input2_train = tf.reshape(input2_train, [-1, 224, 224, 3])\n",
        "        # initialize the optimizer and model\n",
        "        model_d2 = model_alex_cnn()\n",
        "        model_d2.compile(loss=my_loss, optimizer=OPTIMIZER,metrics=[my_acc])\n",
        "        history_d2 = model_d2.fit(input2_train, label2, epochs=NB_EPOCH,verbose=VERBOSE ,validation_split=VALIDATION_SPLIT )\n",
        ""
      ],
      "metadata": {
        "id": "brlBb_REMYcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d0750be-4d5e-461f-8d48-78b5b2ada822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training iteration 0\n",
            "Epoch 1/3\n",
            "(None, 2)\n",
            "(None, 2)\n",
            "(None, 2)\n",
            "(None, 2)\n",
            " [[0 1]\n",
            " [1 0]]\n",
            " [[0.497646451 0.487714976]\n",
            " [0.499586731 0.482378244]]\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6914 - my_acc: 0.5000(None, 2)\n",
            "(None, 2)\n",
            " [[1 0]\n",
            " [0 1]]\n",
            " [[0.496516436 0.497038633]\n",
            " [0.496754646 0.4976466]]\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6914 - my_acc: 0.5000 - val_loss: 0.6931 - val_my_acc: 0.5000\n",
            "Epoch 2/3\n",
            " [[1 0]\n",
            " [0 1]]\n",
            " [[0.505122185 0.49357608]\n",
            " [0.475014955 0.505484045]]\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6827 - my_acc: 1.0000 [[1 0]\n",
            " [0 1]]\n",
            " [[0.494004428 0.497782975]\n",
            " [0.493771911 0.498518854]]\n",
            "1/1 [==============================] - 1s 541ms/step - loss: 0.6827 - my_acc: 1.0000 - val_loss: 0.6929 - val_my_acc: 0.5000\n",
            "Epoch 3/3\n",
            " [[0 1]\n",
            " [1 0]]\n",
            " [[0.483868599 0.477304399]\n",
            " [0.48965475 0.508219719]]\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6995 - my_acc: 0.0000e+00 [[1 0]\n",
            " [0 1]]\n",
            " [[0.493085295 0.498766]\n",
            " [0.493029445 0.498572]]\n",
            "1/1 [==============================] - 1s 535ms/step - loss: 0.6995 - my_acc: 0.0000e+00 - val_loss: 0.6932 - val_my_acc: 0.5000\n",
            "Epoch 1/3\n",
            "(None, 2)\n",
            "(None, 2)\n",
            "(None, 2)\n",
            "(None, 2)\n",
            " [[1 0]\n",
            " [1 0]]\n",
            " [[0.495155424 0.509971]\n",
            " [0.509148657 0.502883434]]\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6953 - my_acc: 0.5000(None, 2)\n",
            "(None, 2)\n",
            " [[0 1]\n",
            " [1 0]]\n",
            " [[0.504199505 0.503619969]\n",
            " [0.503173411 0.503429651]]\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6953 - my_acc: 0.5000 - val_loss: 0.6934 - val_my_acc: 0.0000e+00\n",
            "Epoch 2/3\n",
            " [[1 0]\n",
            " [1 0]]\n",
            " [[0.505382478 0.509496808]\n",
            " [0.503345609 0.509939671]]\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6958 - my_acc: 0.0000e+00 [[0 1]\n",
            " [1 0]]\n",
            " [[0.509485 0.49738878]\n",
            " [0.508812368 0.497077823]]\n",
            "1/1 [==============================] - 1s 532ms/step - loss: 0.6958 - my_acc: 0.0000e+00 - val_loss: 0.6933 - val_my_acc: 0.5000\n",
            "Epoch 3/3\n",
            " [[1 0]\n",
            " [1 0]]\n",
            " [[0.505382538 0.492086083]\n",
            " [0.506972373 0.50586158]]\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6896 - my_acc: 1.0000 [[0 1]\n",
            " [1 0]]\n",
            " [[0.516464293 0.489477187]\n",
            " [0.515651345 0.489197105]]\n",
            "1/1 [==============================] - 1s 507ms/step - loss: 0.6896 - my_acc: 1.0000 - val_loss: 0.6934 - val_my_acc: 0.5000\n",
            "Epoch 1/3\n",
            "(None, 2)\n",
            "(None, 2)\n",
            "(None, 2)\n",
            "(None, 2)\n",
            " [[1 0]\n",
            " [0 1]]\n",
            " [[0.489013135 0.507326245]\n",
            " [0.48152253 0.506737471]]\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6915 - my_acc: 0.5000(None, 2)\n",
            "(None, 2)\n",
            " [[1 0]\n",
            " [0 1]]\n",
            " [[0.498117775 0.502858]\n",
            " [0.498428136 0.503373]]\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6915 - my_acc: 0.5000 - val_loss: 0.6931 - val_my_acc: 0.5000\n",
            "Epoch 2/3\n",
            " [[0 1]\n",
            " [1 0]]\n",
            " [[0.489846528 0.51476568]\n",
            " [0.504742 0.5045138]]\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6869 - my_acc: 1.0000 [[1 0]\n",
            " [0 1]]\n",
            " [[0.499281853 0.502944529]\n",
            " [0.499295175 0.502598882]]\n",
            "1/1 [==============================] - 1s 651ms/step - loss: 0.6869 - my_acc: 1.0000 - val_loss: 0.6932 - val_my_acc: 0.5000\n",
            "Epoch 3/3\n",
            " [[1 0]\n",
            " [0 1]]\n",
            " [[0.490266979 0.511959076]\n",
            " [0.495085627 0.505235195]]\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6961 - my_acc: 0.5000 [[1 0]\n",
            " [0 1]]\n",
            " [[0.499483764 0.502736151]\n",
            " [0.498938054 0.502168655]]\n",
            "1/1 [==============================] - 1s 578ms/step - loss: 0.6961 - my_acc: 0.5000 - val_loss: 0.6932 - val_my_acc: 0.5000\n",
            "Epoch 1/3\n",
            "(None, 2)\n",
            "(None, 2)\n",
            "(None, 2)\n",
            "(None, 2)\n",
            " [[0 1]\n",
            " [0 1]]\n",
            " [[0.497300565 0.497622848]\n",
            " [0.501103 0.497172266]]\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6941 - my_acc: 0.5000(None, 2)\n",
            "(None, 2)\n",
            " [[1 0]\n",
            " [0 1]]\n",
            " [[0.499058366 0.503353477]\n",
            " [0.498602509 0.504102349]]\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6941 - my_acc: 0.5000 - val_loss: 0.6928 - val_my_acc: 0.5000\n",
            "Epoch 2/3\n",
            " [[0 1]\n",
            " [0 1]]\n",
            " [[0.496403545 0.504793346]\n",
            " [0.501230836 0.498276144]]\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6918 - my_acc: 0.5000 [[1 0]\n",
            " [0 1]]\n",
            " [[0.494655818 0.507189572]\n",
            " [0.494240344 0.507627428]]\n",
            "1/1 [==============================] - 1s 511ms/step - loss: 0.6918 - my_acc: 0.5000 - val_loss: 0.6930 - val_my_acc: 0.5000\n",
            "Epoch 3/3\n",
            " [[0 1]\n",
            " [0 1]]\n",
            " [[0.477765113 0.511931837]\n",
            " [0.508894324 0.507157743]]\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6851 - my_acc: 0.5000 [[1 0]\n",
            " [0 1]]\n",
            " [[0.487993121 0.512928307]\n",
            " [0.488091767 0.513306439]]\n",
            "1/1 [==============================] - 1s 532ms/step - loss: 0.6851 - my_acc: 0.5000 - val_loss: 0.6932 - val_my_acc: 0.5000\n",
            "Epoch 1/3\n",
            "(None, 2)\n",
            "(None, 2)\n",
            "(None, 2)\n",
            "(None, 2)\n",
            " [[1 0]\n",
            " [1 0]]\n",
            " [[0.490000278 0.50232625]\n",
            " [0.496876806 0.505354166]]\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7ff11778d9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6984 - my_acc: 0.0000e+00(None, 2)\n",
            "(None, 2)\n",
            " [[0 1]\n",
            " [1 0]]\n",
            " [[0.498134822 0.500824]\n",
            " [0.498612374 0.500820518]]\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff117590b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6984 - my_acc: 0.0000e+00 - val_loss: 0.6930 - val_my_acc: 0.5000\n",
            "Epoch 2/3\n",
            " [[1 0]\n",
            " [1 0]]\n",
            " [[0.500396371 0.496983349]\n",
            " [0.500259578 0.50088048]]\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6924 - my_acc: 0.5000 [[0 1]\n",
            " [1 0]]\n",
            " [[0.501357317 0.498025596]\n",
            " [0.501575112 0.497290373]]\n",
            "1/1 [==============================] - 0s 487ms/step - loss: 0.6924 - my_acc: 0.5000 - val_loss: 0.6929 - val_my_acc: 0.5000\n",
            "Epoch 3/3\n",
            " [[1 0]\n",
            " [1 0]]\n",
            " [[0.499469489 0.501982093]\n",
            " [0.491551876 0.510618329]]\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6986 - my_acc: 0.0000e+00 [[0 1]\n",
            " [1 0]]\n",
            " [[0.50569582 0.493905604]\n",
            " [0.505893946 0.493189275]]\n",
            "1/1 [==============================] - 1s 523ms/step - loss: 0.6986 - my_acc: 0.0000e+00 - val_loss: 0.6929 - val_my_acc: 0.5000\n",
            "Epoch 1/3\n",
            "(None, 2)\n",
            "(None, 2)\n",
            "(None, 2)\n",
            "(None, 2)\n",
            " [[1 0]\n",
            " [0 1]]\n",
            " [[0.502849698 0.503258646]\n",
            " [0.506446242 0.500320554]]\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7ff117707ef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6948 - my_acc: 0.0000e+00(None, 2)\n",
            "(None, 2)\n",
            " [[0 1]\n",
            " [1 0]]\n",
            " [[0.500907719 0.499310046]\n",
            " [0.500642598 0.498830676]]\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff115078830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6948 - my_acc: 0.0000e+00 - val_loss: 0.6931 - val_my_acc: 0.5000\n",
            "Epoch 2/3\n",
            " [[1 0]\n",
            " [0 1]]\n",
            " [[0.500223339 0.501743913]\n",
            " [0.500153661 0.502288282]]\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6930 - my_acc: 0.5000 [[0 1]\n",
            " [1 0]]\n",
            " [[0.501518488 0.499889]\n",
            " [0.500867307 0.499034822]]\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.6930 - my_acc: 0.5000 - val_loss: 0.6931 - val_my_acc: 0.5000\n",
            "Epoch 3/3\n",
            " [[1 0]\n",
            " [0 1]]\n",
            " [[0.499117792 0.496877551]\n",
            " [0.49987784 0.503458679]]\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6917 - my_acc: 1.0000 [[0 1]\n",
            " [1 0]]\n",
            " [[0.501774 0.499757]\n",
            " [0.501200855 0.498920709]]\n",
            "1/1 [==============================] - 1s 510ms/step - loss: 0.6917 - my_acc: 1.0000 - val_loss: 0.6931 - val_my_acc: 0.5000\n",
            "Epoch 1/3\n",
            "(None, 2)\n",
            "(None, 2)\n",
            "(None, 2)\n",
            "(None, 2)\n",
            " [[1 0]\n",
            " [1 0]]\n",
            " [[0.500905 0.502604425]\n",
            " [0.504869938 0.497375816]]\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6917 - my_acc: 0.5000(None, 2)\n",
            "(None, 2)\n",
            " [[0 1]\n",
            " [0 1]]\n",
            " [[0.509064734 0.506168604]\n",
            " [0.508170962 0.505837619]]\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6917 - my_acc: 0.5000 - val_loss: 0.6945 - val_my_acc: 0.0000e+00\n",
            "Epoch 2/3\n",
            " [[1 0]\n",
            " [1 0]]\n",
            " [[0.502379 0.496099502]\n",
            " [0.517724395 0.511496484]]\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6900 - my_acc: 1.0000 [[0 1]\n",
            " [0 1]]\n",
            " [[0.515409052 0.498296291]\n",
            " [0.515549242 0.498033255]]\n",
            "1/1 [==============================] - 0s 381ms/step - loss: 0.6900 - my_acc: 1.0000 - val_loss: 0.7018 - val_my_acc: 0.0000e+00\n",
            "Epoch 3/3\n",
            " [[1 0]\n",
            " [1 0]]\n",
            " [[0.521427333 0.501831234]\n",
            " [0.508248508 0.484307408]]\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6823 - my_acc: 1.0000 [[0 1]\n",
            " [0 1]]\n",
            " [[0.527160108 0.488482624]\n",
            " [0.527848363 0.489607453]]\n",
            "1/1 [==============================] - 0s 387ms/step - loss: 0.6823 - my_acc: 1.0000 - val_loss: 0.7126 - val_my_acc: 0.0000e+00\n",
            "Epoch 1/3\n",
            "(None, 2)\n",
            "(None, 2)\n",
            "(None, 2)\n",
            "(None, 2)\n",
            " [[1 0]\n",
            " [1 0]]\n",
            " [[0.495218486 0.48567009]\n",
            " [0.493659794 0.481301337]]\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6877 - my_acc: 1.0000(None, 2)\n",
            "(None, 2)\n",
            " [[0 1]\n",
            " [1 0]]\n",
            " [[0.495842755 0.492578089]\n",
            " [0.496267229 0.492815107]]\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6877 - my_acc: 1.0000 - val_loss: 0.6931 - val_my_acc: 0.5000\n",
            "Epoch 2/3\n",
            " [[1 0]\n",
            " [1 0]]\n",
            " [[0.502648413 0.481714576]\n",
            " [0.505669594 0.496979982]]\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6858 - my_acc: 1.0000 [[0 1]\n",
            " [1 0]]\n",
            " [[0.500623703 0.483475596]\n",
            " [0.501020133 0.483686924]]\n",
            "1/1 [==============================] - 0s 385ms/step - loss: 0.6858 - my_acc: 1.0000 - val_loss: 0.6931 - val_my_acc: 0.5000\n",
            "Epoch 3/3\n",
            " [[1 0]\n",
            " [1 0]]\n",
            " [[0.484019846 0.471219361]\n",
            " [0.510915756 0.497275323]]\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6866 - my_acc: 1.0000 [[0 1]\n",
            " [1 0]]\n",
            " [[0.50833118 0.470204949]\n",
            " [0.508322597 0.470601]]\n",
            "1/1 [==============================] - 0s 391ms/step - loss: 0.6866 - my_acc: 1.0000 - val_loss: 0.6934 - val_my_acc: 0.5000\n",
            "Epoch 1/3\n",
            "(None, 2)\n",
            "(None, 2)\n",
            "(None, 2)\n",
            "(None, 2)\n",
            " [[1 0]\n",
            " [1 0]]\n",
            " [[0.508904874 0.496255964]\n",
            " [0.493091613 0.48506856]]\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6880 - my_acc: 1.0000(None, 2)\n",
            "(None, 2)\n",
            " [[1 0]\n",
            " [0 1]]\n",
            " [[0.506808519 0.49541378]\n",
            " [0.506907165 0.494383454]]\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6880 - my_acc: 1.0000 - val_loss: 0.6934 - val_my_acc: 0.5000\n",
            "Epoch 2/3\n",
            " [[1 0]\n",
            " [1 0]]\n",
            " [[0.503481209 0.490330935]\n",
            " [0.515252829 0.491315335]]\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6839 - my_acc: 1.0000 [[1 0]\n",
            " [0 1]]\n",
            " [[0.513840735 0.488214165]\n",
            " [0.514052689 0.487100303]]\n",
            "1/1 [==============================] - 0s 379ms/step - loss: 0.6839 - my_acc: 1.0000 - val_loss: 0.6936 - val_my_acc: 0.5000\n",
            "Epoch 3/3\n",
            " [[1 0]\n",
            " [1 0]]\n",
            " [[0.522260427 0.491600662]\n",
            " [0.516216159 0.468859702]]\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6738 - my_acc: 1.0000 [[1 0]\n",
            " [0 1]]\n",
            " [[0.527632117 0.474997401]\n",
            " [0.528737903 0.475410551]]\n",
            "1/1 [==============================] - 0s 382ms/step - loss: 0.6738 - my_acc: 1.0000 - val_loss: 0.6937 - val_my_acc: 0.5000\n",
            "Epoch 1/3\n",
            "(None, 2)\n",
            "(None, 2)\n",
            "(None, 2)\n",
            "(None, 2)\n",
            " [[0 1]\n",
            " [1 0]]\n",
            " [[0.497018754 0.496072024]\n",
            " [0.494255573 0.489921898]]\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6923 - my_acc: 0.5000(None, 2)\n",
            "(None, 2)\n",
            " [[0 1]\n",
            " [1 0]]\n",
            " [[0.496060103 0.491847843]\n",
            " [0.496176749 0.492938787]]\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6923 - my_acc: 0.5000 - val_loss: 0.6934 - val_my_acc: 0.5000\n",
            "Epoch 2/3\n",
            " [[1 0]\n",
            " [0 1]]\n",
            " [[0.504793346 0.49075675]\n",
            " [0.488451958 0.48990792]]\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6893 - my_acc: 1.0000 [[0 1]\n",
            " [1 0]]\n",
            " [[0.494421571 0.492019]\n",
            " [0.49480176 0.49278003]]\n",
            "1/1 [==============================] - 0s 390ms/step - loss: 0.6893 - my_acc: 1.0000 - val_loss: 0.6932 - val_my_acc: 0.5000\n",
            "Epoch 3/3\n",
            " [[1 0]\n",
            " [0 1]]\n",
            " [[0.496092737 0.476341546]\n",
            " [0.502914965 0.491150975]]\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6912 - my_acc: 0.5000 [[0 1]\n",
            " [1 0]]\n",
            " [[0.492453724 0.490164697]\n",
            " [0.492853969 0.490790486]]\n",
            "1/1 [==============================] - 0s 390ms/step - loss: 0.6912 - my_acc: 0.5000 - val_loss: 0.6932 - val_my_acc: 0.5000\n",
            "Epoch 1/3\n",
            "(None, 2)\n",
            "(None, 2)\n",
            "(None, 2)\n",
            "(None, 2)\n",
            " [[0 1]\n",
            " [1 0]]\n",
            " [[0.504648387 0.502474964]\n",
            " [0.507691383 0.502648115]]\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6924 - my_acc: 0.5000(None, 2)\n",
            "(None, 2)\n",
            " [[0 1]\n",
            " [0 1]]\n",
            " [[0.501850784 0.500905335]\n",
            " [0.502665102 0.502441168]]\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6924 - my_acc: 0.5000 - val_loss: 0.6934 - val_my_acc: 0.0000e+00\n",
            "Epoch 2/3\n",
            " [[0 1]\n",
            " [1 0]]\n",
            " [[0.507927775 0.502080739]\n",
            " [0.502694488 0.496949732]]\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6932 - my_acc: 0.5000 [[0 1]\n",
            " [0 1]]\n",
            " [[0.502580822 0.502312958]\n",
            " [0.502644658 0.503621638]]\n",
            "1/1 [==============================] - 0s 378ms/step - loss: 0.6932 - my_acc: 0.5000 - val_loss: 0.6930 - val_my_acc: 0.5000\n",
            "Epoch 3/3\n",
            " [[0 1]\n",
            " [1 0]]\n",
            " [[0.505751848 0.500663459]\n",
            " [0.518493414 0.506549]]\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6914 - my_acc: 0.5000 [[0 1]\n",
            " [0 1]]\n",
            " [[0.503930867 0.504787922]\n",
            " [0.504218876 0.50476712]]\n",
            "1/1 [==============================] - 0s 390ms/step - loss: 0.6914 - my_acc: 0.5000 - val_loss: 0.6928 - val_my_acc: 1.0000\n",
            "Epoch 1/3\n",
            "(None, 2)\n",
            "(None, 2)\n",
            "(None, 2)\n",
            "(None, 2)\n",
            " [[1 0]\n",
            " [0 1]]\n",
            " [[0.507730544 0.491334587]\n",
            " [0.51161164 0.500262439]]\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6919 - my_acc: 0.5000(None, 2)\n",
            "(None, 2)\n",
            " [[1 0]\n",
            " [0 1]]\n",
            " [[0.500055432 0.495375335]\n",
            " [0.500282705 0.493835837]]\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6919 - my_acc: 0.5000 - val_loss: 0.6936 - val_my_acc: 0.5000\n",
            "Epoch 2/3\n",
            " [[0 1]\n",
            " [1 0]]\n",
            " [[0.504444957 0.496175319]\n",
            " [0.510287344 0.49428314]]\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6912 - my_acc: 0.5000 [[1 0]\n",
            " [0 1]]\n",
            " [[0.500415325 0.495102555]\n",
            " [0.499660403 0.493896216]]\n",
            "1/1 [==============================] - 0s 389ms/step - loss: 0.6912 - my_acc: 0.5000 - val_loss: 0.6933 - val_my_acc: 0.5000\n",
            "Epoch 3/3\n",
            " [[1 0]\n",
            " [0 1]]\n",
            " [[0.508604586 0.489680856]\n",
            " [0.500014067 0.495125711]]\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6897 - my_acc: 0.5000 [[1 0]\n",
            " [0 1]]\n",
            " [[0.500816345 0.493975788]\n",
            " [0.49984473 0.492731452]]\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.6897 - my_acc: 0.5000 - val_loss: 0.6932 - val_my_acc: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(n_iteration):\n",
        "\n",
        "    print('testing operation %d'%(k))\n",
        "    for i in range(len(SNR_db)):\n",
        "\n",
        "        SPC_test, test_label1, test_label2 = generate(M, N, int(batch_size * test_size ) )\n",
        "        signal_power = np.mean(pow(SPC, 2))\n",
        "        sigma = math.sqrt(signal_power / (math.sqrt(N) * pow(10, SNR_db[i] / 10)))\n",
        "\n",
        "        input1_test = generate_input(H1_real, H1_image, SPC_test, N, int(batch_size * test_size), sigma)\n",
        "        score1 = model_d1.evaluate(input1_test,test_label1, verbose=VERBOSE)\n",
        "        ERROR_user1[i,k] = 1-score1[1]\n",
        "\n",
        "\n",
        "        input2_test = generate_input(H2_real, H2_image, SPC_test, N, int(batch_size * test_size), sigma)\n",
        "        score2 = model_d2.evaluate(input2_test,test_label2, verbose=VERBOSE)\n",
        "        ERROR_user2[i,k] = 1-score2[1]\n",
        "\n",
        "\n",
        "error1 = np.mean((ERROR_user1),axis=1)\n",
        "error2 = np.mean((ERROR_user2),axis=1)\n"
      ],
      "metadata": {
        "id": "HQ6lfkGJMRXL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "outputId": "8926e7d4-08b4-4fe0-eba4-19d4758bf61b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testing operation 0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-62eecda92efd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0minput1_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH1_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH1_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSPC_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mscore1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_d1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_label1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVERBOSE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mERROR_user1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mscore1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1525, in test_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1514, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1507, in run_step  **\n        outputs = model.test_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1471, in test_step\n        y_pred = self(x, training=False)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_5\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(32, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.semilogy(SNR_db,error1, ls = '--', marker = 'o',label='user1')\n",
        "plt.semilogy(SNR_db,error2, ls = '--', marker = '+',label='user2')\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.ylim(pow(10,-6),pow(10,0) )\n",
        "plt.xlabel('SNR')\n",
        "plt.ylabel('SER')\n",
        "plt.title('SER of user2 in SISO_NOMA BPSK_DNN')\n",
        "plt.savefig('res1')\n",
        "plt.show()\n",
        "\n",
        "print(error1)\n",
        "print(error2)"
      ],
      "metadata": {
        "id": "8lu9izqeMMIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list all data in history\n",
        "# summarize history for accuracy\n",
        "plt.figure()\n",
        "plt.plot(history_d1.history['my_acc'])\n",
        "plt.plot(history_d1.history['val_my_acc'])\n",
        "plt.title('model-1 accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train UE1', 'test UE1'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iieHUeowSPTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list all data in history\n",
        "# summarize history for accuracy\n",
        "plt.figure()\n",
        "plt.plot(history_d2.history['my_acc'])\n",
        "plt.plot(history_d2.history['val_my_acc'])\n",
        "plt.title('model-2 accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train UE2', 'test UE2'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zz7vthE_SQzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for loss\n",
        "plt.figure()\n",
        "plt.plot(history_d1.history['loss'])\n",
        "plt.plot(history_d1.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train UE1', 'test UE1'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Jm3sOC7LSehA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for loss\n",
        "plt.figure()\n",
        "plt.plot(history_d2.history['loss'])\n",
        "plt.plot(history_d2.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train UE2', 'test UE2'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "czS4mJk_SiXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input1_train.shape)\n",
        "print(input2_train.shape)\n",
        "print(input1_test.shape)\n",
        "print(input2_test.shape)\n",
        "\n",
        "print(label1.shape)\n",
        "print(label2.shape)\n",
        "print(test_label1.shape)\n",
        "print(test_label2.shape)\n",
        "\n",
        "print(input1_train[111])\n",
        "print(label1[111])"
      ],
      "metadata": {
        "id": "tIdjdk1aFeGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_d1.save(\"model_dnn_UE1\")\n",
        "model_d2.save(\"mode2_dnn_UE2\")"
      ],
      "metadata": {
        "id": "rae2WEQ2eITL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}